{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab195f9",
   "metadata": {},
   "source": [
    "### Question 1 - Random Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9154c5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{v1: 0.492963376738754, v2: 0.798008175495717, v3: 0.454076149988424, v4: -0.738577190357942, v5: 0.398036886774541}\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, Eq, solve\n",
    "\n",
    "v1, v2, v3, v4, v5 = symbols('v1 v2 v3 v4 v5')\n",
    "\n",
    "e1 = Eq(v1, -0.02 + 0.9*(0.7*v2 + 0.1*v3 + 0.1*v4 + 0.1*v5))\n",
    "e2 = Eq(v2, -0.02 + 0.9*(0.7 + 0.1*v1 + 0.2*v2))\n",
    "e3 = Eq(v3, -0.02 + 0.9*(0.1*v1 + 0.2*v2 + 0.7*v3))\n",
    "e4 = Eq(v4, -0.02 + 0.9*(0.1*v1 + 0.1*v4 + 0.1*v4 + 0.7*(-1)))\n",
    "e5 = Eq(v5, -0.02 + 0.9*(0.7*v1 + 0.3*v5))\n",
    "\n",
    "solutions = solve((e1, e2, e3, e4, e5), (v1, v2, v3, v4, v5))\n",
    "print(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1a00e4",
   "metadata": {},
   "source": [
    "### Question 1 - Optimal Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05629ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{v1: 0.611091928198094, v2: 0.810973504314425, v3: 0.499983444883286, v4: 0.335351115566828, v5: 0.499983444883286}\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, Eq, solve\n",
    "\n",
    "v1, v2, v3, v4, v5 = symbols('v1 v2 v3 v4 v5')\n",
    "\n",
    "e1 = Eq(v1, -0.02 + 0.9*(0.7*v2 + 0.1*v5 + 0.1*v4 + 0.1*v3))\n",
    "e2 = Eq(v2, -0.02 + 0.9*(0.7 + 0.2*v2 + 0.1*v1))\n",
    "e3 = Eq(v3, -0.02 + 0.9*(0.7*v1 + 0.3*v3))\n",
    "e4 = Eq(v4, -0.02 + 0.9*(0.7*v1 + 0.1*v4 + 0.1*v4 + 0.1*(-1)))\n",
    "e5 = Eq(v5, -0.02 + 0.9*(0.7*v1 + 0.3*v5))\n",
    "\n",
    "solutions = solve((e1, e2, e3, e4, e5), (v1, v2, v3, v4, v5))\n",
    "print(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b5124",
   "metadata": {},
   "source": [
    "### Justifying the idea of non-zero probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078df83b",
   "metadata": {},
   "source": [
    "The transition probability for the random policy has a non-zero probability of going backwards. It would be due to of randomness and uncertainty or negative ffedback, non - deterministic dynamics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f8c38a",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e653bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged values for random policy: [0.6110919281980935, 0.8109735043144248, 0.49998344488328617, 0.33535111556682784, 0.49998344488328617]\n"
     ]
    }
   ],
   "source": [
    "def bellman_equation(values, policy):\n",
    "    new_values = [0.0] * len(values)\n",
    "    for i in range(len(values)):\n",
    "        if i == 0:\n",
    "            new_values[i] = -0.02 + 0.9 * (\n",
    "                0.7 * values[1] + 0.1 * values[4] + 0.1 * values[3] + 0.1 * values[2]\n",
    "            )\n",
    "        elif i == 1:\n",
    "            new_values[i] = -0.02 + 0.9 * (\n",
    "                0.7 + 0.2 * values[1] + 0.1 * values[0]\n",
    "            )\n",
    "        elif i == 2:\n",
    "            new_values[i] = -0.02 + 0.9 * (\n",
    "                0.7 * values[0] + 0.3 * values[2]\n",
    "            )\n",
    "        elif i == 3:\n",
    "            new_values[i] = -0.02 + 0.9 * (\n",
    "                0.7 * values[0] + 0.1 * values[3] + 0.1 * values[3] + 0.1 * (-1)\n",
    "            )\n",
    "        elif i == 4:\n",
    "            new_values[i] = -0.02 + 0.9 * (\n",
    "                0.7 * values[0] + 0.3 * values[4]\n",
    "            )\n",
    "    return new_values\n",
    "\n",
    "def main():\n",
    "    num_states = 5\n",
    "    initial_values = [0.0] * num_states\n",
    "    random_policy = [0.25, 0.25, 0.25, 0.25, 0.0]  # Your random policy probabilities\n",
    "\n",
    "    iterations = 100\n",
    "    for i in range(iterations):\n",
    "        initial_values = bellman_equation(initial_values, random_policy)\n",
    "\n",
    "    print(\"Converged values for random policy:\", initial_values)\n",
    "\n",
    "    # Now you can repeat the process with optimal policy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed07c6e",
   "metadata": {},
   "source": [
    "As it iterates, the values become to more closer to the values we got from problem 1. \n",
    "Thus, this iteration converges to the random policy, as well as optimal policy.\n",
    "\n",
    "The convergence is driven by the nature of the Bellman Equation. The iterative process updates the value estimates of states based on the expected future rewards and the probabilities of transitioning to other states. As the iteration progress, the value estimates gradually become more accurate and stable, ultimately reaching a point where further updates have a negligible impact. This is the reason why the value converges. \n",
    "\n",
    "In the case of the optimal policy, the value function converges to the optimal values because the Bellman optimality equation ensures that each iteration improves the value estimates according to the optimal policy's criteria.\n",
    "\n",
    "In the case of the random policy, the value function will also converge to a steady state, reflecting the expected rewards under the given policy. However, since the random policy doesn't optimize actions, the value function might not represent the optimal policy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
